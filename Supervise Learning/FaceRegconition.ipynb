{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcc8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "✅ Số ảnh: 492, nhãn: {np.str_('Stephanie'), np.str_('Judy'), np.str_('Neri'), np.str_('Valery'), np.str_('Joan'), np.str_('Joshua'), np.str_('Laura'), np.str_('Screenshot 2025-07-23 151535'), np.str_('Stephen'), np.str_('Gavyn'), np.str_('Screenshot 2025-07-23 150534'), np.str_('Screenshot 2025-07-23 151353'), np.str_('Ahmet'), np.str_('Rocco'), np.str_('Screenshot 2025-07-23 151205'), np.str_('Jason'), np.str_('Massoud'), np.str_('Tatiana'), np.str_('Robert'), np.str_('John'), np.str_('Screenshot 2025-07-23 151358'), np.str_('Aaron'), np.str_('Screenshot 2025-07-23 151159'), np.str_('Screenshot 2025-07-23 151155'), np.str_('Screenshot 2025-07-23 151551'), np.str_('Sohail'), np.str_('Xavier'), np.str_('Screenshot 2025-07-23 151624'), np.str_('Screenshot 2025-07-23 150559'), np.str_('Martha'), np.str_('Juan'), np.str_('Lucio'), np.str_('Pamela'), np.str_('Valorie'), np.str_('Michelle'), np.str_('Screenshot 2025-07-23 151051'), np.str_('Lleyton'), np.str_('Screenshot 2025-07-23 150901'), np.str_('Corliss'), np.str_('Screenshot 2025-07-23 150707'), np.str_('Myung'), np.str_('Gary'), np.str_('Donna'), np.str_('Scott'), np.str_('Vassilis'), np.str_('Screenshot 2025-07-23 150854'), np.str_('Hideki'), np.str_('Screenshot 2025-07-23 150849'), np.str_('Emmanuel'), np.str_('Screenshot 2025-07-23 150832'), np.str_('Paul'), np.str_('Felix'), np.str_('Screenshot 2025-07-23 150842'), np.str_('Naomi'), np.str_('Dominic'), np.str_('Screenshot 2025-07-23 150519'), np.str_('Daryl'), np.str_('Flor'), np.str_('Anthony'), np.str_('Screenshot 2025-07-23 150655'), np.str_('Screenshot 2025-07-23 150622'), np.str_('Aitor'), np.str_('Kathleen'), np.str_('Crandall'), np.str_('Cheryl'), np.str_('Michael'), np.str_('Screenshot 2025-07-23 151233'), np.str_('Carla'), np.str_('Sergei'), np.str_('Amanda'), np.str_('Greg'), np.str_('Screenshot 2025-07-23 151711'), np.str_('Screenshot 2025-07-23 151614'), np.str_('Screenshot 2025-07-23 151445'), np.str_('Krishna'), np.str_('Screenshot 2025-07-23 150837'), np.str_('Eddy'), np.str_('Screenshot 2025-07-23 150758'), np.str_('Bo'), np.str_('Screenshot 2025-07-23 150937'), np.str_('Al'), np.str_('Screenshot 2025-07-23 150747'), np.str_('Hank'), np.str_('Teri'), np.str_('Ashraf'), np.str_('Stan'), np.str_('Screenshot 2025-07-23 151409'), np.str_('Roger'), np.str_('Jack'), np.str_('Chuck'), np.str_('Toni'), np.str_('Screenshot 2025-07-23 151620'), np.str_('Screenshot 2025-07-23 150930'), np.str_('Screenshot 2025-07-23 150508'), np.str_('Saeb'), np.str_('Screenshot 2025-07-23 151533'), np.str_('Rohman'), np.str_('Teddy'), np.str_('Dan'), np.str_('Brook'), np.str_('Thomas'), np.str_('Screenshot 2025-07-23 151549'), np.str_('Gene'), np.str_('Ron'), np.str_('Screenshot 2025-07-23 150636'), np.str_('Screenshot 2025-07-23 150522'), np.str_('Patty'), np.str_('Eduard'), np.str_('Amy'), np.str_('Jim'), np.str_('Rose'), np.str_('Lena'), np.str_('Pak'), np.str_('Sergey'), np.str_('Ridley'), np.str_('Donald'), np.str_('sample.jpg'), np.str_('Brian'), np.str_('Screenshot 2025-07-23 150710'), np.str_('Frank'), np.str_('Carlos'), np.str_('Screenshot 2025-07-23 151125'), np.str_('Talisa'), np.str_('Natalie'), np.str_('Andy'), np.str_('Fernando'), np.str_('Andrew'), np.str_('Suh'), np.str_('Screenshot 2025-07-23 150751'), np.str_('Screenshot 2025-07-23 150651'), np.str_('Jana'), np.str_('Iain'), np.str_('Screenshot 2025-07-23 151539'), np.str_('Bill'), np.str_('Andrea'), np.str_('Screenshot 2025-07-23 150612'), np.str_('Screenshot 2025-07-23 151241'), np.str_('Tyler'), np.str_('Screenshot 2025-07-23 151428'), np.str_('Wang'), np.str_('Kwon'), np.str_('Kaio'), np.str_('Marcos'), np.str_('Elias'), np.str_('Jennifer'), np.str_('Jacques'), np.str_('Hillary'), np.str_('James'), np.str_('Screenshot 2025-07-23 151628'), np.str_('Oscar'), np.str_('Celia'), np.str_('Screenshot 2025-07-23 150908'), np.str_('Screenshot 2025-07-23 151114'), np.str_('Keanu'), np.str_('Screenshot 2025-07-23 151151'), np.str_('Dino'), np.str_('Gordon'), np.str_('Nicolas'), np.str_('Screenshot 2025-07-23 151106'), np.str_('Linda'), np.str_('Screenshot 2025-07-23 151142'), np.str_('Screenshot 2025-07-23 151458'), np.str_('Trudi'), np.str_('Jesse'), np.str_('Griffin'), np.str_('Screenshot 2025-07-23 151730'), np.str_('Hikmat'), np.str_('Sharon'), np.str_('Carolina'), np.str_('Alex'), np.str_('Darlene'), np.str_('Lynne'), np.str_('Screenshot 2025-07-23 151506'), np.str_('Bryan'), np.str_('Screenshot 2025-07-23 151716'), np.str_('Dwayne'), np.str_('Romario'), np.str_('Manuel'), np.str_('Ciro'), np.str_('Roy'), np.str_('Mireya'), np.str_('Sivan'), np.str_('Pio'), np.str_('Jaqueline'), np.str_('Angela'), np.str_('Tom'), np.str_('Rob'), np.str_('Jayne'), np.str_('Screenshot 2025-07-23 150912'), np.str_('Eric'), np.str_('Janice'), np.str_('Screenshot 2025-07-23 151721'), np.str_('Screenshot 2025-07-23 150541'), np.str_('Mladen'), np.str_('Screenshot 2025-07-23 150616'), np.str_('Nancy'), np.str_('Emma'), np.str_('Laurence'), np.str_('Jeremy'), np.str_('Marc'), np.str_('Screenshot 2025-07-23 151543'), np.str_('Terry'), np.str_('Screenshot 2025-07-23 150553'), np.str_('SJ'), np.str_('Lee'), np.str_('Alimzhan'), np.str_('Screenshot 2025-07-23 151224'), np.str_('Randall'), np.str_('George'), np.str_('Sada'), np.str_('Hans'), np.str_('Sereyvuth'), np.str_('Zurab'), np.str_('Zeljko'), np.str_('Chris'), np.str_('Screenshot 2025-07-23 150715'), np.str_('Screenshot 2025-07-23 150629'), np.str_('Takeo'), np.str_('Screenshot 2025-07-23 151724'), np.str_('Patsy'), np.str_('Screenshot 2025-07-23 150722'), np.str_('Edward'), np.str_('Bruce'), np.str_('Grant'), np.str_('Clifford'), np.str_('Teresa'), np.str_('Matt'), np.str_('Kristen'), np.str_('Christine'), np.str_('Henry'), np.str_('Christoph'), np.str_('Dale'), np.str_('Mary'), np.str_('Julio'), np.str_('Wayne'), np.str_('Screenshot 2025-07-23 150538'), np.str_('Screenshot 2025-07-23 151642'), np.str_('Steffi'), np.str_('Screenshot 2025-07-23 150529'), np.str_('Timbul'), np.str_('Kevin'), np.str_('Screenshot 2025-07-23 151609'), np.str_('Kate'), np.str_('Screenshot 2025-07-23 151149'), np.str_('Kostya'), np.str_('Hartmut'), np.str_('Mario'), np.str_('Ascencion'), np.str_('Tim'), np.str_('Colleen'), np.str_('Mel'), np.str_('Screenshot 2025-07-23 151228'), np.str_('Screenshot 2025-07-23 151713'), np.str_('Barry'), np.str_('Sebastian'), np.str_('Madeleine'), np.str_('Tyron'), np.str_('Screenshot 2025-07-23 151449'), np.str_('William'), np.str_('Screenshot 2025-07-23 151718'), np.str_('Lloyd'), np.str_('Screenshot 2025-07-23 151053'), np.str_('Screenshot 2025-07-23 151211'), np.str_('Screenshot 2025-07-23 151607'), np.str_('Jimmy'), np.str_('Mike'), np.str_('Mark'), np.str_('Tommy'), np.str_('Screenshot 2025-07-23 150602'), np.str_('Craig'), np.str_('Screenshot 2025-07-23 151216'), np.str_('Shavon'), np.str_('Screenshot 2025-07-23 151611'), np.str_('Screenshot 2025-07-23 151237'), np.str_('Jerry'), np.str_('Julian'), np.str_('Bing'), np.str_('Naoto'), np.str_('Stella'), np.str_('Steven'), np.str_('Screenshot 2025-07-23 150515'), np.str_('Screenshot 2025-07-23 151635'), np.str_('Norah'), np.str_('Screenshot 2025-07-23 151640'), np.str_('Maureen'), np.str_('Sidney'), np.str_('Screenshot 2025-07-23 151726'), np.str_('Rick'), np.str_('Steny'), np.str_('Billy'), np.str_('Screenshot 2025-07-23 150626'), np.str_('Peter'), np.str_('Screenshot 2025-07-23 150803'), np.str_('Francis'), np.str_('Bob'), np.str_('Screenshot 2025-07-23 151059'), np.str_('Gen'), np.str_('Screenshot 2025-07-23 150845'), np.str_('Chip'), np.str_('Charles'), np.str_('Tiffany'), np.str_('Sheryl'), np.str_('Cristian'), np.str_('Maria'), np.str_('Gerard'), np.str_('Santiago'), np.str_('Osrat'), np.str_('Screenshot 2025-07-23 150633'), np.str_('Gabrielle'), np.str_('Mira'), np.str_('Screenshot 2025-07-23 151048'), np.str_('Steve'), np.str_('Screenshot 2025-07-23 151436'), np.str_('Dick'), np.str_('Erika'), np.str_('Marcella'), np.str_('Wanda'), np.str_('Adam'), np.str_('Ajit'), np.str_('Screenshot 2025-07-23 150512'), np.str_('Screenshot 2025-07-23 150548'), np.str_('Jonathan'), np.str_('Screenshot 2025-07-23 151346'), np.str_('Inocencio'), np.str_('David'), np.str_('Betty'), np.str_('Monica'), np.str_('Javier'), np.str_('Ernie'), np.str_('Shane'), np.str_('Screenshot 2025-07-23 150701'), np.str_('Olivier'), np.str_('Screenshot 2025-07-23 151632'), np.str_('Ted'), np.str_('Ronald'), np.str_('Tara')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/multiclass.py:213: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  y_type = type_of_target(y, input_name=\"y\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã train & lưu model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load model\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "def load_cropface_embeddings(folder):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.lower().endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        label = filename.split('_')[0]  # Lấy tên trước dấu _\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Không đọc được ảnh: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (112, 112))  # đảm bảo đúng input size\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Trích embedding từ ảnh đã crop\n",
    "        embedding = app.models['recognition'].get_feat(img).flatten()\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(embeddings), np.array(labels)\n",
    "\n",
    "# Bước 1: Load ảnh và trích embedding\n",
    "X, y = load_cropface_embeddings(\"facecrop\")\n",
    "print(f\"✅ Số ảnh: {len(X)}, nhãn: {set(y)}\")\n",
    "\n",
    "if len(X) < 2 or len(set(y)) < 2:\n",
    "    raise ValueError(\"⚠️ Không đủ dữ liệu để train SVM. Cần ít nhất 2 ảnh từ 2 nhãn khác nhau.\")\n",
    "\n",
    "# Bước 2: Encode nhãn\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Bước 3: Train SVM\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(X, y_encoded)\n",
    "\n",
    "# Bước 4: Lưu model\n",
    "joblib.dump(clf, \"svm_face_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"✅ Đã train & lưu model.\")\n",
    "\n",
    "# OMG IT WORKEDDDDDDDD AJNWDJNAWDJKNAWJDNKAWKJDAWNJDAWKJNDAWJKDJAKWDANWKJDJKNAWKDNJAWNJK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244295cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 397, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 752, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_16130/1655882791.py\", line 5, in <module>\n",
      "    from insightface.app import FaceAnalysis\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/insightface/__init__.py\", line 18, in <module>\n",
      "    from . import app\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/insightface/app/__init__.py\", line 2, in <module>\n",
      "    from .mask_renderer import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/insightface/app/mask_renderer.py\", line 4, in <module>\n",
      "    import albumentations as A\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py\", line 24, in <module>\n",
      "    from .pytorch import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/pytorch/__init__.py\", line 1, in <module>\n",
      "    from .transforms import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/pytorch/transforms.py\", line 15, in <module>\n",
      "    import torch\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1711403380909/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "✅ Nhận diện: Ev (độ tự tin: 93.59%)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Load SVM model và LabelEncoder\n",
    "clf = joblib.load(\"svm_face_model.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Load InsightFace\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "def predict_face(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Không thể đọc ảnh: {image_path}\")\n",
    "\n",
    "    img = cv2.resize(img, (112, 112))  # resize cho đúng kích thước\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Tạo giả định face object vì ảnh đã crop rồi\n",
    "    face = type('Face', (object,), {})()\n",
    "    face.kps = None  # Không có landmark\n",
    "    embedding = app.models['recognition'].get_feat(img).flatten()\n",
    "\n",
    "    # Predict\n",
    "    pred = clf.predict([embedding])\n",
    "    prob = clf.predict_proba([embedding])\n",
    "\n",
    "    label = label_encoder.inverse_transform(pred)[0]\n",
    "    confidence = prob[0][pred[0]]\n",
    "\n",
    "    print(f\"✅ Nhận diện: {label} (độ tự tin: {confidence:.2%})\")\n",
    "\n",
    "# Test một ảnh\n",
    "predict_face(\"datasets/testcrop/test.png\")  # Đổi path nếu cần\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda3510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Load SVM và label encoder\n",
    "clf = joblib.load(\"svm_face_model.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Load InsightFace\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "# Khởi động webcam (nếu có webcam thật, hoặc đang dùng video mô phỏng)\n",
    "cap = cv2.VideoCapture(\"output.avi\")  # Đổi thành đường dẫn video nếu cần\n",
    "\n",
    "frame_count = 0  # Đếm frame để debug nếu cần\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển sang RGB để insightface dùng\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect face\n",
    "    faces = app.get(img_rgb)\n",
    "\n",
    "    for face in faces:\n",
    "        if face.embedding is None:\n",
    "            continue  # Không nhận diện được\n",
    "\n",
    "        embedding = face.embedding\n",
    "        pred = clf.predict([embedding])[0]\n",
    "        prob = clf.predict_proba([embedding])[0][pred]\n",
    "\n",
    "        label = label_encoder.inverse_transform([pred])[0]\n",
    "\n",
    "        # Vẽ bounding box + label\n",
    "        x1, y1, x2, y2 = map(int, face.bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{label} ({prob:.2%})\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # ✅ Thay vì imshow, ta lưu ảnh ra file (hoặc log ra console)\n",
    "    output_path = f\"output/frame_{frame_count}.jpg\"\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f\"[INFO] Frame {frame_count} saved to {output_path}\")\n",
    "    frame_count += 1\n",
    "\n",
    "    # Chạy thử 50 frame rồi dừng (tránh chạy mãi trong Docker)\n",
    "    if frame_count >= 50:\n",
    "        break\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c53a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Current dir: /workspace/Supervise Learning\n",
      "📂 Files in dir: ['.gradio', '.ipynb_checkpoints', 'CNN.ipynb', 'datasets', 'facecrop', 'FaceRegconition.ipynb', 'image', 'label_encoder.pkl', 'lfw_funneled', 'ML.ipynb', 'mnist_cnn_model.h5', 'PredictbyType.ipynb', 'PredictbyValue.ipynb', 'svm_face_model.pkl', 'Test Drawing Program.ipynb', 'yolov8n-face.pt']\n",
      "🎥 Opening video: output.avi\n",
      "❌ Không mở được video. Có thể do:\n",
      "  1. Video không tồn tại\n",
      "  2. OpenCV không hỗ trợ codec (thiếu FFMPEG)\n",
      "  3. File bị lỗi\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "video_path = \"output.avi\"\n",
    "print(\"📁 Current dir:\", os.getcwd())\n",
    "print(\"📂 Files in dir:\", os.listdir(\".\"))\n",
    "print(\"🎥 Opening video:\", video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Không mở được video. Có thể do:\")\n",
    "    print(\"  1. Video không tồn tại\")\n",
    "    print(\"  2. OpenCV không hỗ trợ codec (thiếu FFMPEG)\")\n",
    "    print(\"  3. File bị lỗi\")\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
